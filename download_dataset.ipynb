{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRWvCDaaSrC3",
        "outputId": "374cb2d7-e977-439c-b070-37614df38127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting data download...\n",
            "==================================================\n",
            "\n",
            "üìä Downloading Real-Madrid data...\n",
            "üì• Downloading Real-Madrid statistics...\n",
            "üì• Downloading Real-Madrid match logs...\n",
            "‚ùå Failed to get 2023-2024 matches for Real-Madrid: No tables found\n",
            "‚ùå Failed to get 2024-2025 matches for Real-Madrid: No tables found\n",
            "\n",
            "üìä Downloading Qairat-Almaty data...\n",
            "üì• Downloading Qairat-Almaty statistics...\n",
            "üì• Downloading Qairat-Almaty match logs...\n",
            "‚ùå Failed to get 2023-2024 matches for Qairat-Almaty: No tables found\n",
            "‚ùå Failed to get 2024-2025 matches for Qairat-Almaty: No tables found\n",
            "\n",
            "üéØ Creating training dataset...\n",
            "üì• Creating training dataset...\n",
            "‚úÖ Saved football_training_dataset.csv (1000 matches)\n",
            "\n",
            "Outcome distribution:\n",
            "outcome\n",
            "0    682\n",
            "1    206\n",
            "2    112\n",
            "Name: count, dtype: int64\n",
            "0 = Team1 wins, 1 = Draw, 2 = Team2 wins\n",
            "\n",
            "‚úÖ All data downloaded! Files created:\n",
            "- real-madrid_*_stats.csv\n",
            "- qairat-almaty_*_stats.csv\n",
            "- real-madrid_match_logs.csv\n",
            "- qairat-almaty_match_logs.csv\n",
            "- football_training_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "# PART 1: DATA COLLECTION AND CSV EXPORT\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class FBRefCSVDownloader:\n",
        "    \"\"\"\n",
        "    Download FBRef data and save as CSV files for notebook use\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "        }\n",
        "\n",
        "    def download_team_stats_csv(self, team_name, team_id, season=\"2024-2025\"):\n",
        "        \"\"\"\n",
        "        Download team statistics and save as CSV\n",
        "        \"\"\"\n",
        "        print(f\"üì• Downloading {team_name} statistics...\")\n",
        "\n",
        "        url = f\"https://fbref.com/en/squads/{team_id}/{season}/{team_name}-Stats\"\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url, headers=self.headers)\n",
        "            time.sleep(3)\n",
        "\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            all_stats = {}\n",
        "\n",
        "            # Download multiple stat tables\n",
        "            table_ids = {\n",
        "                'standard': 'stats_standard',\n",
        "                'shooting': 'stats_shooting',\n",
        "                'passing': 'stats_passing',\n",
        "                'defense': 'stats_defense',\n",
        "                'possession': 'stats_possession'\n",
        "            }\n",
        "\n",
        "            for stat_type, table_id in table_ids.items():\n",
        "                try:\n",
        "                    table = soup.find('table', {'id': table_id})\n",
        "                    if table:\n",
        "                        df = pd.read_html(str(table))[0]\n",
        "\n",
        "                        # Clean multi-level columns if they exist\n",
        "                        if isinstance(df.columns, pd.MultiIndex):\n",
        "                            df.columns = ['_'.join(col).strip() for col in df.columns]\n",
        "\n",
        "                        # Add metadata\n",
        "                        df['Team'] = team_name\n",
        "                        df['Season'] = season\n",
        "                        df['StatType'] = stat_type\n",
        "\n",
        "                        # Save individual CSV\n",
        "                        filename = f\"{team_name.lower()}_{stat_type}_{season.replace('-', '_')}.csv\"\n",
        "                        df.to_csv(filename, index=False)\n",
        "                        print(f\"‚úÖ Saved {filename}\")\n",
        "\n",
        "                        all_stats[stat_type] = df\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Failed to get {stat_type} for {team_name}: {e}\")\n",
        "\n",
        "            # Save combined stats file\n",
        "            if all_stats:\n",
        "                combined_filename = f\"{team_name.lower()}_all_stats_{season.replace('-', '_')}.csv\"\n",
        "\n",
        "                # Combine all stats with common columns\n",
        "                base_df = all_stats['standard'] if 'standard' in all_stats else pd.DataFrame()\n",
        "\n",
        "                for stat_type, df in all_stats.items():\n",
        "                    if stat_type != 'standard' and not df.empty:\n",
        "                        # Merge on common columns (usually Player name)\n",
        "                        common_cols = set(base_df.columns) & set(df.columns)\n",
        "                        if 'Player' in common_cols or any('Player' in col for col in common_cols):\n",
        "                            try:\n",
        "                                base_df = base_df.merge(df, on=list(common_cols), how='outer', suffixes=('', f'_{stat_type}'))\n",
        "                            except:\n",
        "                                # If merge fails, just concatenate\n",
        "                                pass\n",
        "\n",
        "                base_df.to_csv(combined_filename, index=False)\n",
        "                print(f\"‚úÖ Saved combined: {combined_filename}\")\n",
        "\n",
        "            return all_stats\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error downloading {team_name} data: {e}\")\n",
        "            return None\n",
        "\n",
        "    def download_match_logs_csv(self, team_name, team_id, seasons=['2023-2024', '2024-2025']):\n",
        "        \"\"\"\n",
        "        Download match history and save as CSV\n",
        "        \"\"\"\n",
        "        print(f\"üì• Downloading {team_name} match logs...\")\n",
        "\n",
        "        all_matches = []\n",
        "\n",
        "        for season in seasons:\n",
        "            try:\n",
        "                url = f\"https://fbref.com/en/squads/{team_id}/{season}/matchlogs/all_comps/schedule/{team_name}-Scores-and-Fixtures-All-Competitions\"\n",
        "\n",
        "                response = requests.get(url, headers=self.headers)\n",
        "                time.sleep(3)\n",
        "\n",
        "                # Try to find the fixtures table\n",
        "                tables = pd.read_html(response.content)\n",
        "\n",
        "                if tables:\n",
        "                    matches_df = tables[0]  # Usually the first table\n",
        "\n",
        "                    # Clean columns\n",
        "                    if isinstance(matches_df.columns, pd.MultiIndex):\n",
        "                        matches_df.columns = ['_'.join(col).strip() for col in matches_df.columns]\n",
        "\n",
        "                    # Add metadata\n",
        "                    matches_df['Team'] = team_name\n",
        "                    matches_df['Season'] = season\n",
        "\n",
        "                    all_matches.append(matches_df)\n",
        "                    print(f\"‚úÖ {season}: {len(matches_df)} matches\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed to get {season} matches for {team_name}: {e}\")\n",
        "\n",
        "        if all_matches:\n",
        "            combined_matches = pd.concat(all_matches, ignore_index=True)\n",
        "            filename = f\"{team_name.lower()}_match_logs.csv\"\n",
        "            combined_matches.to_csv(filename, index=False)\n",
        "            print(f\"‚úÖ Saved {filename}\")\n",
        "            return combined_matches\n",
        "\n",
        "        return None\n",
        "\n",
        "    def create_training_dataset_csv(self):\n",
        "        \"\"\"\n",
        "        Create a training dataset with similar matchups for ML\n",
        "        \"\"\"\n",
        "        print(\"üì• Creating training dataset...\")\n",
        "\n",
        "        # This creates a synthetic training dataset based on typical football patterns\n",
        "        # In practice, you'd collect this from multiple teams and leagues\n",
        "\n",
        "        np.random.seed(42)\n",
        "        n_matches = 1000\n",
        "\n",
        "        # Generate realistic football match data\n",
        "        training_data = []\n",
        "\n",
        "        for i in range(n_matches):\n",
        "            # Team strengths (0-100 scale)\n",
        "            team1_strength = np.random.normal(75, 15)  # Stronger teams like Real Madrid\n",
        "            team2_strength = np.random.normal(55, 12)  # Weaker teams like Kairat\n",
        "\n",
        "            # Ensure realistic bounds\n",
        "            team1_strength = np.clip(team1_strength, 40, 95)\n",
        "            team2_strength = np.clip(team2_strength, 30, 85)\n",
        "\n",
        "            # Generate match features\n",
        "            strength_diff = team1_strength - team2_strength\n",
        "            home_advantage = np.random.choice([0, 1], p=[0.5, 0.5])  # 0=away, 1=home for team1\n",
        "            competition_level = np.random.choice([6, 7, 8, 9], p=[0.3, 0.3, 0.3, 0.1])  # UEFA competition levels\n",
        "\n",
        "            # Team statistics based on strength\n",
        "            team1_goals_per_game = 1.2 + (team1_strength / 100) * 1.8 + np.random.normal(0, 0.2)\n",
        "            team2_goals_per_game = 0.8 + (team2_strength / 100) * 1.5 + np.random.normal(0, 0.2)\n",
        "\n",
        "            team1_goals_against = 0.5 + ((100 - team1_strength) / 100) * 1.2 + np.random.normal(0, 0.15)\n",
        "            team2_goals_against = 0.7 + ((100 - team2_strength) / 100) * 1.4 + np.random.normal(0, 0.15)\n",
        "\n",
        "            # Shot statistics\n",
        "            team1_shots_per_game = 10 + (team1_strength / 100) * 8 + np.random.normal(0, 1)\n",
        "            team2_shots_per_game = 8 + (team2_strength / 100) * 6 + np.random.normal(0, 1)\n",
        "\n",
        "            team1_shot_accuracy = 30 + (team1_strength / 100) * 25 + np.random.normal(0, 3)\n",
        "            team2_shot_accuracy = 25 + (team2_strength / 100) * 20 + np.random.normal(0, 3)\n",
        "\n",
        "            # Possession\n",
        "            team1_possession = 45 + (team1_strength / 100) * 20 + np.random.normal(0, 3)\n",
        "            team2_possession = 100 - team1_possession\n",
        "\n",
        "            # Determine outcome based on probabilities influenced by strength difference\n",
        "            if strength_diff > 20:\n",
        "                outcome_probs = [0.75, 0.15, 0.10]  # Strong favorite\n",
        "            elif strength_diff > 10:\n",
        "                outcome_probs = [0.60, 0.25, 0.15]  # Moderate favorite\n",
        "            elif strength_diff > 0:\n",
        "                outcome_probs = [0.50, 0.30, 0.20]  # Slight favorite\n",
        "            else:\n",
        "                outcome_probs = [0.35, 0.30, 0.35]  # Even match\n",
        "\n",
        "            # Add home advantage effect\n",
        "            if home_advantage == 1:  # Team1 at home\n",
        "                outcome_probs = [outcome_probs[0] + 0.1, outcome_probs[1], outcome_probs[2] - 0.1]\n",
        "\n",
        "            outcome = np.random.choice([0, 1, 2], p=outcome_probs)  # 0=Team1 wins, 1=Draw, 2=Team2 wins\n",
        "\n",
        "            # Create row\n",
        "            row = {\n",
        "                'team1_strength': team1_strength,\n",
        "                'team2_strength': team2_strength,\n",
        "                'strength_difference': strength_diff,\n",
        "                'home_advantage': home_advantage,\n",
        "                'competition_level': competition_level,\n",
        "                'team1_goals_per_game': max(0, team1_goals_per_game),\n",
        "                'team2_goals_per_game': max(0, team2_goals_per_game),\n",
        "                'team1_goals_against_per_game': max(0, team1_goals_against),\n",
        "                'team2_goals_against_per_game': max(0, team2_goals_against),\n",
        "                'team1_shots_per_game': max(0, team1_shots_per_game),\n",
        "                'team2_shots_per_game': max(0, team2_shots_per_game),\n",
        "                'team1_shot_accuracy': np.clip(team1_shot_accuracy, 10, 60),\n",
        "                'team2_shot_accuracy': np.clip(team2_shot_accuracy, 10, 60),\n",
        "                'team1_possession': np.clip(team1_possession, 25, 75),\n",
        "                'team2_possession': np.clip(team2_possession, 25, 75),\n",
        "                'outcome': outcome\n",
        "            }\n",
        "\n",
        "            training_data.append(row)\n",
        "\n",
        "        # Create DataFrame and save\n",
        "        training_df = pd.DataFrame(training_data)\n",
        "        training_df.to_csv('football_training_dataset.csv', index=False)\n",
        "        print(f\"‚úÖ Saved football_training_dataset.csv ({len(training_df)} matches)\")\n",
        "\n",
        "        # Show distribution\n",
        "        print(\"\\nOutcome distribution:\")\n",
        "        print(training_df['outcome'].value_counts())\n",
        "        print(\"0 = Team1 wins, 1 = Draw, 2 = Team2 wins\")\n",
        "\n",
        "        return training_df\n",
        "\n",
        "def download_all_data():\n",
        "    \"\"\"\n",
        "    Download all required data and save as CSV files\n",
        "    \"\"\"\n",
        "    downloader = FBRefCSVDownloader()\n",
        "\n",
        "    print(\"üöÄ Starting data download...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Team IDs from FBRef\n",
        "    teams = {\n",
        "        'Real-Madrid': '53a2f082',\n",
        "        'Qairat-Almaty': '768fb565'  # Kairat's FBRef ID\n",
        "    }\n",
        "\n",
        "    # Download team statistics\n",
        "    for team_name, team_id in teams.items():\n",
        "        print(f\"\\nüìä Downloading {team_name} data...\")\n",
        "        downloader.download_team_stats_csv(team_name, team_id)\n",
        "        downloader.download_match_logs_csv(team_name, team_id)\n",
        "\n",
        "    # Create training dataset\n",
        "    print(f\"\\nüéØ Creating training dataset...\")\n",
        "    training_df = downloader.create_training_dataset_csv()\n",
        "\n",
        "    print(f\"\\n‚úÖ All data downloaded! Files created:\")\n",
        "    print(\"- real-madrid_*_stats.csv\")\n",
        "    print(\"- qairat-almaty_*_stats.csv\")\n",
        "    print(\"- real-madrid_match_logs.csv\")\n",
        "    print(\"- qairat-almaty_match_logs.csv\")\n",
        "    print(\"- football_training_dataset.csv\")\n",
        "\n",
        "# ============================================================================\n",
        "# PART 2: NOTEBOOK CODE - USE THIS IN YOUR JUPYTER NOTEBOOK\n",
        "# ============================================================================\n",
        "\n",
        "\"\"\"\n",
        "JUPYTER NOTEBOOK CODE - Copy this section into your notebook\n",
        "\"\"\"\n",
        "\n",
        "def load_and_prepare_data():\n",
        "    \"\"\"\n",
        "    Load CSV files and prepare for ML - USE THIS IN YOUR NOTEBOOK\n",
        "    \"\"\"\n",
        "    print(\"üìÇ Loading CSV files...\")\n",
        "\n",
        "    try:\n",
        "        # Load training dataset\n",
        "        training_df = pd.read_csv('football_training_dataset.csv')\n",
        "        print(f\"‚úÖ Loaded training data: {training_df.shape}\")\n",
        "\n",
        "        # Load team statistics\n",
        "        real_madrid_stats = {}\n",
        "        kairat_stats = {}\n",
        "\n",
        "        # Try to load Real Madrid stats\n",
        "        try:\n",
        "            real_madrid_stats['standard'] = pd.read_csv('real-madrid_standard_2024_2025.csv')\n",
        "            print(\"‚úÖ Loaded Real Madrid standard stats\")\n",
        "        except:\n",
        "            print(\"‚ö†Ô∏è  Real Madrid standard stats not found\")\n",
        "\n",
        "        try:\n",
        "            real_madrid_stats['shooting'] = pd.read_csv('real-madrid_shooting_2024_2025.csv')\n",
        "            print(\"‚úÖ Loaded Real Madrid shooting stats\")\n",
        "        except:\n",
        "            print(\"‚ö†Ô∏è  Real Madrid shooting stats not found\")\n",
        "\n",
        "        # Try to load Kairat stats\n",
        "        try:\n",
        "            kairat_stats['standard'] = pd.read_csv('qairat-almaty_standard_2024_2025.csv')\n",
        "            print(\"‚úÖ Loaded Kairat standard stats\")\n",
        "        except:\n",
        "            print(\"‚ö†Ô∏è  Kairat standard stats not found\")\n",
        "\n",
        "        try:\n",
        "            kairat_stats['shooting'] = pd.read_csv('qairat-almaty_shooting_2024_2025.csv')\n",
        "            print(\"‚úÖ Loaded Kairat shooting stats\")\n",
        "        except:\n",
        "            print(\"‚ö†Ô∏è  Kairat shooting stats not found\")\n",
        "\n",
        "        # Load match logs\n",
        "        try:\n",
        "            real_matches = pd.read_csv('real-madrid_match_logs.csv')\n",
        "            print(f\"‚úÖ Loaded Real Madrid matches: {len(real_matches)}\")\n",
        "        except:\n",
        "            print(\"‚ö†Ô∏è  Real Madrid match logs not found\")\n",
        "            real_matches = None\n",
        "\n",
        "        try:\n",
        "            kairat_matches = pd.read_csv('qairat-almaty_match_logs.csv')\n",
        "            print(f\"‚úÖ Loaded Kairat matches: {len(kairat_matches)}\")\n",
        "        except:\n",
        "            print(\"‚ö†Ô∏è  Kairat match logs not found\")\n",
        "            kairat_matches = None\n",
        "\n",
        "        return {\n",
        "            'training_data': training_df,\n",
        "            'real_madrid_stats': real_madrid_stats,\n",
        "            'kairat_stats': kairat_stats,\n",
        "            'real_matches': real_matches,\n",
        "            'kairat_matches': kairat_matches\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading data: {e}\")\n",
        "        return None\n",
        "\n",
        "def train_prediction_model(training_df):\n",
        "    \"\"\"\n",
        "    Train ML models on the loaded data - USE THIS IN YOUR NOTEBOOK\n",
        "    \"\"\"\n",
        "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.model_selection import train_test_split, cross_val_score\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "    print(\"ü§ñ Training ML models...\")\n",
        "\n",
        "    # Prepare features and target\n",
        "    feature_columns = [col for col in training_df.columns if col != 'outcome']\n",
        "    X = training_df[feature_columns]\n",
        "    y = training_df['outcome']\n",
        "\n",
        "    print(f\"Features: {len(feature_columns)}\")\n",
        "    print(f\"Samples: {len(X)}\")\n",
        "    print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Train multiple models\n",
        "    models = {\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nüìä Training {name}...\")\n",
        "\n",
        "        # Train\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Evaluate\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Cross-validation\n",
        "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
        "\n",
        "        results[name] = {\n",
        "            'model': model,\n",
        "            'accuracy': accuracy,\n",
        "            'cv_mean': cv_scores.mean(),\n",
        "            'cv_std': cv_scores.std()\n",
        "        }\n",
        "\n",
        "        print(f\"Accuracy: {accuracy:.3f}\")\n",
        "        print(f\"CV Score: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
        "\n",
        "    # Select best model\n",
        "    best_model_name = max(results.keys(), key=lambda k: results[k]['cv_mean'])\n",
        "    best_model = results[best_model_name]['model']\n",
        "\n",
        "    print(f\"\\nüèÜ Best model: {best_model_name}\")\n",
        "\n",
        "    return {\n",
        "        'models': results,\n",
        "        'best_model': best_model,\n",
        "        'scaler': scaler,\n",
        "        'feature_columns': feature_columns,\n",
        "        'best_model_name': best_model_name\n",
        "    }\n",
        "\n",
        "def predict_real_madrid_vs_kairat(model_package, real_stats, kairat_stats):\n",
        "    \"\"\"\n",
        "    Make prediction for Real Madrid vs Kairat - USE THIS IN YOUR NOTEBOOK\n",
        "    \"\"\"\n",
        "    print(\"üîÆ Predicting Real Madrid vs Kairat...\")\n",
        "\n",
        "    # Create features for the matchup\n",
        "    features = create_match_features(real_stats, kairat_stats)\n",
        "\n",
        "    # Convert to array\n",
        "    feature_array = np.array([list(features.values())]).reshape(1, -1)\n",
        "\n",
        "    # Scale features\n",
        "    feature_array_scaled = model_package['scaler'].transform(feature_array)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model_package['best_model'].predict(feature_array_scaled)[0]\n",
        "    probabilities = model_package['best_model'].predict_proba(feature_array_scaled)[0]\n",
        "\n",
        "    outcomes = ['Real Madrid Win', 'Draw', 'Kairat Win']\n",
        "\n",
        "    result = {\n",
        "        'predicted_outcome': outcomes[prediction],\n",
        "        'probabilities': {\n",
        "            'Real Madrid Win': probabilities[0],\n",
        "            'Draw': probabilities[1],\n",
        "            'Kairat Win': probabilities[2]\n",
        "        },\n",
        "        'confidence': max(probabilities),\n",
        "        'features_used': features\n",
        "    }\n",
        "\n",
        "    return result\n",
        "\n",
        "def create_match_features(real_stats, kairat_stats):\n",
        "    \"\"\"\n",
        "    Create features for Real Madrid vs Kairat prediction\n",
        "    \"\"\"\n",
        "    # This creates mock features - replace with actual stats from your CSV files\n",
        "    features = {\n",
        "        'team1_strength': 85,  # Real Madrid strength\n",
        "        'team2_strength': 55,  # Kairat strength\n",
        "        'strength_difference': 30,\n",
        "        'home_advantage': 0,  # 0 = neutral, 1 = Kairat home\n",
        "        'competition_level': 8,  # Champions League level\n",
        "        'team1_goals_per_game': 2.3,\n",
        "        'team2_goals_per_game': 1.1,\n",
        "        'team1_goals_against_per_game': 0.8,\n",
        "        'team2_goals_against_per_game': 1.4,\n",
        "        'team1_shots_per_game': 16.5,\n",
        "        'team2_shots_per_game': 10.2,\n",
        "        'team1_shot_accuracy': 45.2,\n",
        "        'team2_shot_accuracy': 32.1,\n",
        "        'team1_possession': 62.5,\n",
        "        'team2_possession': 37.5\n",
        "    }\n",
        "\n",
        "    # TODO: Replace these mock values with actual calculations from your CSV data\n",
        "    # Example:\n",
        "    # if 'standard' in real_stats:\n",
        "    #     rm_df = real_stats['standard']\n",
        "    #     features['team1_goals_per_game'] = rm_df['Gls'].iloc[0] / rm_df['MP'].iloc[0]\n",
        "\n",
        "    return features\n",
        "\n",
        "# COMPLETE NOTEBOOK WORKFLOW\n",
        "def complete_prediction_workflow():\n",
        "    \"\"\"\n",
        "    Complete workflow for your Jupyter notebook - USE THIS AS MAIN FUNCTION\n",
        "    \"\"\"\n",
        "    print(\"üöÄ REAL MADRID vs KAIRAT PREDICTION WORKFLOW\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Step 1: Load data\n",
        "    data = load_and_prepare_data()\n",
        "    if not data:\n",
        "        print(\"‚ùå Failed to load data. Please run the download script first.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Train models\n",
        "    model_package = train_prediction_model(data['training_data'])\n",
        "\n",
        "    # Step 3: Make prediction\n",
        "    prediction = predict_real_madrid_vs_kairat(\n",
        "        model_package,\n",
        "        data['real_madrid_stats'],\n",
        "        data['kairat_stats']\n",
        "    )\n",
        "\n",
        "    # Step 4: Display results\n",
        "    print(f\"\\nüéØ PREDICTION RESULTS\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"Predicted Outcome: {prediction['predicted_outcome']}\")\n",
        "    print(f\"Model Used: {model_package['best_model_name']}\")\n",
        "    print(f\"Confidence: {prediction['confidence']:.3f}\")\n",
        "\n",
        "    print(f\"\\nüìä PROBABILITIES:\")\n",
        "    for outcome, prob in prediction['probabilities'].items():\n",
        "        print(f\"  {outcome}: {prob:.3f} ({prob*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nüìà FEATURES USED:\")\n",
        "    for feature, value in prediction['features_used'].items():\n",
        "        print(f\"  {feature}: {value}\")\n",
        "\n",
        "    return prediction\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run this to download all CSV files\n",
        "    download_all_data()"
      ]
    }
  ]
}